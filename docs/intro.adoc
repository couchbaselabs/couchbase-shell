== Introduction

Couchbase Shell is fully featured, so it does not only contain commands related to couchbase but is actually built on top of a general purpose shell called https://www.nushell.sh/[nushell]. This allows you to interact with the file system or any other command available on your machine, making it a great tool for both operational and development tasks on top of Couchbase.

The following introduction only touches on the basic concepts to make you productive quickly. We recommend also checking out the great https://www.nushell.sh/documentation.html[nushell documentation] so you can get the most out of it.

=== Navigating the Shell

Commands take inputs and produce output in a structured manner, most often represented as tables. Note how both the generic `ls` command and the couchbase-specific `buckets get` command both produce a table as their output:

```
â¯ ls
â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 #  â”‚ name         â”‚ type â”‚ size     â”‚ modified
â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  0 â”‚ CHANGELOG.md â”‚ File â”‚    977 B â”‚ 3 hours ago
  1 â”‚ Cargo.lock   â”‚ File â”‚ 133.8 KB â”‚ 6 hours ago
  2 â”‚ Cargo.toml   â”‚ File â”‚   1.6 KB â”‚ 3 hours ago
  3 â”‚ LICENSE      â”‚ File â”‚  11.4 KB â”‚ 2 months ago
  4 â”‚ README.md    â”‚ File â”‚   6.3 KB â”‚ 3 hours ago
  5 â”‚ docs         â”‚ Dir  â”‚    288 B â”‚ 27 mins ago
  6 â”‚ examples     â”‚ Dir  â”‚     96 B â”‚ 2 months ago
  7 â”‚ jupyter      â”‚ Dir  â”‚    128 B â”‚ 2 weeks ago
  8 â”‚ src          â”‚ Dir  â”‚    224 B â”‚ 3 hours ago
  9 â”‚ target       â”‚ Dir  â”‚    192 B â”‚ 2 months ago
 10 â”‚ ui-assets    â”‚ Dir  â”‚    832 B â”‚ 3 weeks ago
â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

```
> buckets get
â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 # â”‚ cluster â”‚                 name                 â”‚   type    â”‚ replicas â”‚ ram_quota â”‚ flush_enabled â”‚ min_durability_level 
â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 0 â”‚ local   â”‚ 529dafb7-78d0-4baa-aa33-ba01fbc50af6 â”‚ couchbase â”‚        1 â”‚  100.0 MB â”‚ No            â”‚ none                 
 1 â”‚ local   â”‚ 4b78e6f0-f69d-460b-a698-a46dfe7173c2 â”‚ couchbase â”‚        1 â”‚  100.0 MB â”‚ No            â”‚ none                 
 2 â”‚ local   â”‚ d3a01765-2a66-41e4-b201-a2cea57a23ab â”‚ couchbase â”‚        1 â”‚  100.0 MB â”‚ No            â”‚ none                 
 3 â”‚ local   â”‚ 97568ca9-665d-4949-b343-e2649a741f5a â”‚ couchbase â”‚        1 â”‚  100.0 MB â”‚ No            â”‚ none                 
 4 â”‚ local   â”‚ 181ce90d-19d1-4745-8100-a9d49c59dd02 â”‚ couchbase â”‚        1 â”‚  100.0 MB â”‚ No            â”‚ none                 
 5 â”‚ local   â”‚ 97b23720-a6fc-425e-896c-75cfd07319a1 â”‚ couchbase â”‚        1 â”‚  100.0 MB â”‚ No            â”‚ none                 
 6 â”‚ local   â”‚ beer-sample                          â”‚ couchbase â”‚        1 â”‚  100.0 MB â”‚ No            â”‚ none                 
 7 â”‚ local   â”‚ travel-sample                        â”‚ couchbase â”‚        3 â”‚  100.0 MB â”‚ No            â”‚ none                 
â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

You can pipe the output into other commands, for example if you only want to see buckets that have `sample` in their name you can utilize the `where` command:

```
> buckets get | where name =~ "sample"
â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 # â”‚ cluster â”‚     name      â”‚   type    â”‚ replicas â”‚ ram_quota â”‚ flush_enabled â”‚ min_durability_level 
â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 0 â”‚ local   â”‚ beer-sample   â”‚ couchbase â”‚        1 â”‚  100.0 MB â”‚ No            â”‚ none                 
 1 â”‚ local   â”‚ travel-sample â”‚ couchbase â”‚        3 â”‚  100.0 MB â”‚ No            â”‚ none                 
â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

In a similar fashion you can turn this structured table into other output formats, for example JSON:

```
> buckets get | where name =~ "sample" | to json --pretty 2
[
  {
    "cluster": "local",
    "name": "beer-sample",
    "type": "couchbase",
    "replicas": 1,
    "ram_quota": 100000000,
    "flush_enabled": false,
    "min_durability_level": "none"
  },
  {
    "cluster": "local",
    "name": "travel-sample",
    "type": "couchbase",
    "replicas": 3,
    "ram_quota": 100000000,
    "flush_enabled": false,
    "min_durability_level": "none"
  }
]
```

Exactly this type of composition takes the unix philosophy of "do one thing well" and meshes it together with the idea of flexible structured pipelines. This allows to build powerful compositions that help you in your daily operations with Couchbase, both from a developer or operations point of view.

=== Getting Help

Other than using this documentation for help, each command can be called with `-h` or `--help` to get information about potential flags, arguments and subcommands. Also, some commands provide additional examples.

```
> buckets -h
Perform bucket management operations

Usage:
  > buckets <subcommand> {flags} 

Subcommands:
  buckets config - Shows the bucket config (low level)
  buckets create - Creates a bucket
  buckets drop - Drops buckets through the HTTP API
  buckets flush - Flushes buckets through the HTTP API
  buckets get - Fetches buckets through the HTTP API
  buckets load-sample - Load a sample bucket
  buckets update - Updates a bucket

Flags:
  -h, --help: Display this help message
```

Some commands (like the one above) only act as groupings for subcommands, like `from`, `to` or `doc`. Since they do not serve a purpose on their own, they will render their help output automatically:

```
> doc
Perform document operations against a bucket or collection

Usage:
  > doc <subcommand> {flags} 

Subcommands:
  doc get - Fetches a document through the data service
  doc insert - Insert a document through the data service
  doc remove - Removes a document through the data service
  doc replace - Replace a document through the data service
  doc upsert - Upsert (insert or override) a document through the data service

Flags:
  -h, --help: Display this help message
```

=== The Prompt explained
Couchbase Shell uses a custom, two line prompt to show you exactly in what environment you are working in right now. Since you can connect to different clusters, switch buckets etc. it is important to know what is currently "active". Here is a sample prompt that will greet you when starting the shell:

```
ðŸ‘¤ Administrator at ðŸ  local in ðŸ›«  travel-sample
>
```

It tells you that your user is `Administrator`, the current active cluster identifier is `local` and the active bucket is `travel-sample`. Note that the emoji for the active bucket changes if you use a regular bucket vs. the sample buckets we ship (if you are curious, try loading the `beer-sample` as well!).

In the second line, your actual user prompt starts.

=== Loading Data into the Shell

If you want to import data into Couchbase, or just load it into the shell for further processing, there are different commands available to help you. Once the data is loaded into the shell it can be sent to one of the couchbase save commands like `doc upsert`. Depending on the structure of the data, you may also need to tweak it a little bit so it can be properly stored.

The `open` command will look at file endings and try to decode it automatically. Imagine a file named `user.json` in your current directy with the following content: `{"name": "Michael", "age": 32}`.

```
> open user.json
â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€
 name â”‚ Michael 
 age  â”‚ 32      
â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

As you can see, the `open` command already decoded the JSON document into the tabular format. If the filename would only be `user`, the import would look like this instead:

```
> open user
{"name": "Michael", "age": 32}
```

If you are dealing with data that cannot be decoded automatically, you can use the various `from` subcommands to help with decoding. In our case we use `from json`:

```
> open user | from json
â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€
 name â”‚ Michael 
 age  â”‚ 32      
â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

TIP: look at the many different import formats `from` supports, including csv, xml, yaml and even sqlite. With this simple tool at hand you are able to load many different data formats quickly and import them into couchbase!

=== Exporting Data from the Shell

The export counterparts to `open` and `from`, are `save` and `to`. You can use both command to take tabular data from the shell and store it in files of the needed target format.

Like `open`, `save` will try to discern the format from the file ending. The following example will load a JSON file and save it as CSV:

```
> cat user.json
{"name":"Michael","age":32}
```

```
> open user.json | save user.csv
```

```
> cat user.csv
name,age
Michael,32
```

This example is dealing with only one row for simplicity, but you can save as many rows as you need in one file. 

As a motivating example, the following snippet runs a N1QL query and stores the result as a csv file:

```
> query "select airportname,city,country from `travel-sample` where type = 'airport' limit 10" | save output.csv
```

```
> cat output.csv
airportname,city,country
Calais Dunkerque,Calais,France
Peronne St Quentin,Peronne,France
Les Loges,Nangis,France
Couterne,Bagnole-de-l'orne,France
Bray,Albert,France
Le Touquet Paris Plage,Le Tourquet,France
Denain,Valenciennes,France
Glisy,Amiens,France
La Garenne,Agen,France
Cazaux,Cazaux,France
```
