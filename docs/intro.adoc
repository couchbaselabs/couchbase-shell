== Introduction

Couchbase Shell is fully featured, so it does not only contain commands related to couchbase but is actually built on top of a general purpose shell called https://www.nushell.sh/[nushell]. This allows you to interact with the file system or any other command available on your machine, making it a great tool for both operational and development tasks on top of Couchbase.

The following introduction only touches on the basic concepts to make you productive quickly. We recommend also checking out the great https://www.nushell.sh/book[nushell documentation] so you can get the most out of it.

=== Navigating the Shell

Commands take inputs and produce output in a structured manner, most often represented as tables. Note how both the generic `ls` command and the couchbase-specific `buckets` command both produce a table as their output:

```
> ls
────┬──────────────┬──────┬──────────┬────────────────
 #  │     name     │ type │   size   │    modified    
────┼──────────────┼──────┼──────────┼────────────────
  0 │ CHANGELOG.md │ File │   4.8 KB │ 2 hours ago    
  1 │ Cargo.lock   │ File │ 170.2 KB │ 16 minutes ago 
  2 │ Cargo.toml   │ File │   1.8 KB │ 16 minutes ago 
  3 │ LICENSE      │ File │  11.4 KB │ 2 days ago     
  4 │ README.md    │ File │   8.6 KB │ 9 minutes ago  
  5 │ docs         │ Dir  │    544 B │ 2 days ago     
  6 │ examples     │ Dir  │    192 B │ 2 days ago     
  7 │ jupyter      │ Dir  │    128 B │ 2 days ago     
  8 │ src          │ Dir  │    256 B │ 2 days ago     
  9 │ target       │ Dir  │    224 B │ 32 minutes ago 
 10 │ tests        │ Dir  │    224 B │ 2 days ago     
────┴──────────────┴──────┴──────────┴────────────────
```

```
> buckets
───┬──────────┬───────────────┬───────────┬──────────┬──────────────────────┬───────────┬───────────────┬────────┬───────
 # │ database │     name      │   type    │ replicas │ min_durability_level │ ram_quota │ flush_enabled │ status │ cloud 
───┼──────────┼───────────────┼───────────┼──────────┼──────────────────────┼───────────┼───────────────┼────────┼───────
 0 │ default  │ beer-sample   │ couchbase │        1 │ none                 │  209.7 MB │ false         │        │ false 
 1 │ default  │ default       │ couchbase │        1 │ none                 │  104.9 MB │ true          │        │ false 
 2 │ default  │ targetBucket  │ couchbase │        0 │ none                 │  104.9 MB │ true          │        │ false 
 3 │ default  │ travel-sample │ couchbase │        1 │ none                 │  209.7 MB │ false         │        │ false 
───┴──────────┴───────────────┴───────────┴──────────┴──────────────────────┴───────────┴───────────────┴────────┴───────
```

You can pipe the output into other commands, for example if you only want to see buckets that have `sample` in their name you can utilize the `where` command:

```
> buckets | where name =~ "sample"
───┬──────────┬───────────────┬───────────┬──────────┬──────────────────────┬───────────┬───────────────┬────────┬───────
 # │ database │     name      │   type    │ replicas │ min_durability_level │ ram_quota │ flush_enabled │ status │ cloud 
───┼──────────┼───────────────┼───────────┼──────────┼──────────────────────┼───────────┼───────────────┼────────┼───────
 0 │ default  │ beer-sample   │ couchbase │        1 │ none                 │  209.7 MB │ false         │        │ false 
 1 │ default  │ travel-sample │ couchbase │        1 │ none                 │  209.7 MB │ false         │        │ false 
───┴──────────┴───────────────┴───────────┴──────────┴──────────────────────┴───────────┴───────────────┴────────┴───────
```

In a similar fashion you can turn this structured table into other output formats, for example JSON:

```
> buckets | where name =~ "sample" | to json --pretty 2
[
  {
    "database": "default",
    "name": "beer-sample",
    "type": "couchbase",
    "replicas": 1,
    "min_durability_level": "none",
    "ram_quota": 209715200,
    "flush_enabled": false,
    "status": "",
    "cloud": false
  },
  {
    "database": "default",
    "name": "travel-sample",
    "type": "couchbase",
    "replicas": 1,
    "min_durability_level": "none",
    "ram_quota": 209715200,
    "flush_enabled": false,
    "status": "",
    "cloud": false
  }
]
```

Exactly this type of composition takes the unix philosophy of "do one thing well" and meshes it together with the idea of flexible structured pipelines. This allows to build powerful compositions that help you in your daily operations with Couchbase, both from a developer or operations point of view.

=== Getting Help

Other than using this documentation for help, each command can be called with `-h` or `--help` to get information about potential flags, arguments and subcommands. Also, some commands provide additional examples.

```
> buckets -h
Perform bucket management operations

Usage:
  > buckets <subcommand> {flags} 

Subcommands:
  buckets config - Shows the bucket config (low level)
  buckets create - Creates a bucket
  buckets drop - Drops buckets through the HTTP API
  buckets flush - Flushes buckets through the HTTP API
  buckets get - Fetches buckets through the HTTP API
  buckets load-sample - Load a sample bucket
  buckets update - Updates a bucket

Flags:
  -h, --help: Display this help message
  --databases <string>: the databases which should be contacted
```

Some commands (like the one above) only act as groupings for subcommands, like `from`, `to` or `doc`. Since they do not serve a purpose on their own, they will render their help output automatically:

```
> doc
Perform document operations against a bucket or collection

Usage:
  > doc <subcommand> {flags} 

Subcommands:
  doc get - Fetches a document through the data service
  doc insert - Insert a document through the data service
  doc remove - Removes a document through the data service
  doc replace - Replace a document through the data service
  doc upsert - Upsert (insert or override) a document through the data service

Flags:
  -h, --help: Display this help message
```

=== The Prompt explained
Couchbase Shell uses a custom, two line prompt to show you exactly in what environment you are working in right now. Since you can connect to different databases, switch buckets etc. it is important to know what is currently "active". Here is a sample prompt that will greet you when starting the shell:

```
👤 Administrator at 🏠 local in 🗄 travel-sample
>
```

It tells you that your user is `Administrator`, the current active database identifier is `local` and the active bucket is `travel-sample`.

If you have an active scope or collection set then the prompt will also update to reflect that:

```
👤 Administrator 🏠 dev.local in 🗄 travel-sample.myscope.mycollection
>
```

In the second line, your actual user prompt starts.

=== Pivot mode

Sometimes data is easier to see if the table is pivoted so that the columns become rows and rows become columns.
For example the `nodes` command detailed below, by default the output will look like:

```
> nodes
───┬──────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────
 # │ database │ hostnam │ status  │ service │ version │   os    │ memory_ │ memory_
   │          │    e    │         │    s    │         │         │  total  │  free
───┼──────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────
 0 │ local    │ 127.0.0 │ healthy │ analyti │ 6.5.1-6 │ x86_64- │ 34.4 GB │  8.4 GB
   │          │ .1:8091 │         │ cs,even │ 299-ent │ apple-d │         │
   │          │         │         │ ting,se │ erprise │ arwin17 │         │
   │          │         │         │ arch,in │         │ .7.0    │         │
   │          │         │         │ dexing, │         │         │         │
   │          │         │         │ kv,quer │         │         │         │
   │          │         │         │ y       │         │         │         │
───┴──────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────
```

This is easier to see if the table is pivoted to:

```
> nodes
───────────────┬─────────────────────────────────────────────
 database      │ local
 hostname      │ 127.0.0.1:8091
 status        │ healthy
 services      │ analytics,eventing,search,indexing,kv,query
 version       │ 6.5.1-6299-enterprise
 os            │ x86_64-apple-darwin17.7.0
 memory_total  │ 34.4 GB
 memory_free   │ 8.4 GB
───────────────┴─────────────────────────────────────────────
```

Nushell offers a couple of ways to set pivoting mode:

* `config set pivot_mode off` this is the default setting where pivoting is turned off.
* `config set pivot_mode auto` (*recommended*) will allow Nushell to determine when to apply pivoting (typically when there is only one row in the results).
* `config set pivot_mode always` will cause tables to always be pivoted.

=== Loading Data into the Shell

If you want to import data into Couchbase, or just load it into the shell for further processing, there are different commands available to help you. Once the data is loaded into the shell it can be sent to one of the couchbase save commands like `doc upsert`. Depending on the structure of the data, you may also need to tweak it a little bit so it can be properly stored.

The `open` command will look at file endings and try to decode it automatically. Imagine a file named `user.json` in your current directy with the following content: `{"name": "Michael", "age": 32}`.

```
> open user.json
───┬─────────┬─────
 # │  name   │ age 
───┼─────────┼─────
 0 │ Michael │ 32  
───┴─────────┴─────
```

As you can see, the `open` command already decoded the JSON document into the tabular format. If the filename would only be `user`, the import would look like this instead:

```
> open user
{"name": "Michael", "age": 32}
```

If you are dealing with data that cannot be decoded automatically, you can use the various `from` subcommands to help with decoding. In our case we use `from json`:

```
> open user | from json
───┬─────────┬─────
 # │  name   │ age 
───┼─────────┼─────
 0 │ Michael │ 32  
───┴─────────┴─────
```

TIP: look at the many different import formats `from` supports, including csv, xml, yaml and even sqlite. With this simple tool at hand you are able to load many different data formats quickly and import them into couchbase!

=== Exporting Data from the Shell

The export counterparts to `open` and `from`, are `save` and `to`. You can use both command to take tabular data from the shell and store it in files of the needed target format.

Like `open`, `save` will try to discern the format from the file ending. The following example will load a JSON file and save it as CSV:

```
> cat user.json
{"name":"Michael","age":32}
```

```
> open user.json | save user.csv
```

```
> cat user.csv
name,age
Michael,32
```

This example is dealing with only one row for simplicity, but you can save as many rows as you need in one file. 

As a motivating example, the following snippet runs a N1QL query and stores the result as a csv file:

```
> query "select airportname,city,country from `travel-sample` where type = 'airport' limit 10" | save output.csv
```

```
> cat output.csv
airportname,city,country
Calais Dunkerque,Calais,France
Peronne St Quentin,Peronne,France
Les Loges,Nangis,France
Couterne,Bagnole-de-l'orne,France
Bray,Albert,France
Le Touquet Paris Plage,Le Tourquet,France
Denain,Valenciennes,France
Glisy,Amiens,France
La Garenne,Agen,France
Cazaux,Cazaux,France
```
